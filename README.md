# Assistant RAG avec Mistral

Ce projet implÃ©mente un assistant virtuel basÃ© sur le modÃ¨le Mistral, utilisant la technique de Retrieval-Augmented Generation (RAG) pour fournir des rÃ©ponses prÃ©cises et contextuelles Ã  partir d'une base de connaissances personnalisÃ©e.

## FonctionnalitÃ©s

- ğŸ” **Recherche sÃ©mantique** avec FAISS pour trouver les documents pertinents
- ğŸ§  **Classification des requÃªtes** pour dÃ©terminer si une recherche RAG est nÃ©cessaire
- âš™ï¸ **ParamÃ¨tres personnalisables** (modÃ¨le, nombre de documents, score minimum)

## PrÃ©requis

- Python 3.9+ 
- ClÃ© API Mistral (obtenue sur [console.mistral.ai](https://console.mistral.ai/))

## Installation

1. **Cloner le dÃ©pÃ´t**

```bash
git clone <url-du-repo>
cd <nom-du-repo>
```

2. **CrÃ©er un environnement virtuel**

```bash
# CrÃ©ation de l'environnement virtuel
python -m venv venv

# Activation de l'environnement virtuel
# Sur Windows
venv\Scripts\activate
# Sur macOS/Linux
source venv/bin/activate
```

3. **Installer les dÃ©pendances**

```bash
pip install -r requirements.txt
```

4. **Configurer la clÃ© API**

CrÃ©ez un fichier `.env` Ã  la racine du projet avec le contenu suivant :

```
MISTRAL_API_KEY=votre_clÃ©_api_mistral
```

## Structure du projet

```
.
â”œâ”€â”€ chatbot.py              # Application Streamlit principale
â”œâ”€â”€ indexer.py              # Script pour rÃ©cupÃ©rer et indexer les documents
â”œâ”€â”€ inputs/                 # Dossier pour les documents sources
â”œâ”€â”€ vector_db/              # Dossier pour l'index FAISS et les chunks
â”œâ”€â”€ utils/                  # Modules utilitaires
â”‚   â”œâ”€â”€ config.py           # Configuration de l'application
â”‚   â””â”€â”€ vector_store.py     # Gestion de l'index vectoriel
```

## Utilisation

### 1. RÃ©cupÃ©rer les Ã©vÃ¨nements et indexer les documents

ExÃ©cutez le script d'indexation pour rÃ©cupÃ©rer, traiter les Ã©vÃ¨nements et crÃ©er l'index FAISS :

```bash
python indexer.py
```
options:

**--overwrite-input** *pour Ã©craser le fichier de donnÃ©es si prÃ©sent*

**--no-overwrite-input** *pour ne pas Ã©craser le fichier de donnÃ©es si prÃ©sent (dÃ©faut)*


Ce script va :
1. Charger les Ã©vÃ¨nements depuis le site Openagenda
2. DÃ©couper les Ã©vÃ¨nements en chunks
3. GÃ©nÃ©rer des embeddings avec Mistral
4. CrÃ©er un index FAISS pour la recherche sÃ©mantique
5. Sauvegarder l'index et les chunks dans le dossier `vector_db/`

### 3. Lancer l'application

```bash
streamlit run chatbot.py
```

L'application sera accessible Ã  l'adresse http://localhost:8501 dans votre navigateur.

## FonctionnalitÃ©s principales

### Classification des requÃªtes

L'application dÃ©termine automatiquement si une question nÃ©cessite une recherche RAG ou si une rÃ©ponse directe du modÃ¨le Mistral est suffisante. Cela permet d'optimiser les performances et la pertinence des rÃ©ponses.

## Modules principaux

### `utils/vector_store.py`

GÃ¨re l'index vectoriel FAISS et la recherche sÃ©mantique :
- Chargement et dÃ©coupage des documents
- GÃ©nÃ©ration des embeddings avec Mistral
- CrÃ©ation et interrogation de l'index FAISS

## Personnalisation

Vous pouvez personnaliser l'application en modifiant les paramÃ¨tres dans `utils/config.py` :
- Chemin et nom du ficher de donnÃ©es
- Chemin et noms des fichiers de l'index Faiss et les chunks
- ModÃ¨les Mistral utilisÃ©s
- Taille des chunks et chevauchement
- Nombre de documents par dÃ©faut
- Nom de la commune ou organisation
